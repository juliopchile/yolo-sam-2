{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "# Specify the path to the main directory, this is the segment-anything-2 path\n",
    "main_directory = \"/home/asdasd/segment-anything-2\"\n",
    "\n",
    "# Change the current working directory to the main directory\n",
    "os.chdir(main_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use bfloat16 for the entire notebook\n",
    "torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16).__enter__()\n",
    "\n",
    "if torch.cuda.get_device_properties(0).major >= 8:\n",
    "    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions to show results of YOLO segmentations, using OpenCV (Not recomended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_yolo_masks_tensor(segmentation_result):\n",
    "    \"\"\"\n",
    "    Resizes YOLO segmentation masks to their original image shape.\n",
    "\n",
    "    This function takes a segmentation result from a YOLO model that contains masks,\n",
    "    resizes each mask to the original shape of the image from which it was predicted,\n",
    "    and returns the resized masks as a NumPy array of type uint8.\n",
    "\n",
    "    Parameters:\n",
    "    segmentation_result (list): A list of segmentation result objects. Each object should\n",
    "                                have an attribute `masks` with two properties:\n",
    "                                - `data`: A torch tensor of shape (N, H, W) where N is the \n",
    "                                          number of masks, H is the height, and W is the width.\n",
    "                                - `orig_shape`: A tuple (original_height, original_width) which\n",
    "                                                represents the original shape of the image.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: A NumPy array of resized masks of shape (N, original_height, original_width) and type uint8.\n",
    "                Each mask is resized to the original dimensions of the image.\n",
    "                \n",
    "    Example:\n",
    "    segmentation_result = model(input)\n",
    "    resized_masks = resize_yolo_masks_tensor(segmentation_result)\n",
    "    \"\"\"\n",
    "\n",
    "    original_shape = segmentation_result[0].masks.orig_shape\n",
    "    masks = segmentation_result[0].masks.data  # masks.shape = torch.Size([N, H, W]) = (mask_number, height, width)\n",
    "    \n",
    "    # Reshape the masks tensor to add a channel dimension which is needed for F.interpolate\n",
    "    masks = masks.unsqueeze(1)  # masks.shape becomes torch.Size([N, 1, H, W])\n",
    "    \n",
    "    # Interpolate the masks to the original_shape\n",
    "    resized_masks = F.interpolate(masks, size=original_shape, mode='nearest')\n",
    "    \n",
    "    # Remove the channel dimension\n",
    "    resized_masks = resized_masks.squeeze(1)  # resized_masks.shape becomes torch.Size([N, original_shape[0], original_shape[1]])\n",
    "    \n",
    "    # Convert the resized masks to a NumPy array and ensure type uint8\n",
    "    resized_masks = resized_masks.cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    return resized_masks\n",
    "\n",
    "\n",
    "def draw_rectangles(canvas, rectangles, line_color=(0, 255, 0)):\n",
    "    \"\"\"\n",
    "    Draws rectangles on a copy of the canvas image.\n",
    "\n",
    "    Args:\n",
    "        canvas (numpy.ndarray): The original image to draw rectangles on.\n",
    "        rectangles (list of tuples): List of [x, y, w, h] where (x, y) is the top-left corner and (w, h) is the width and height of the rectangle.\n",
    "        line_color (tuple): Color of the rectangle border in BGR format. Default is green.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A new image with rectangles drawn on it, keeping the original image intact.\n",
    "    \"\"\"\n",
    "    # Create a copy of the canvas image\n",
    "    image_with_boxes = canvas.copy()\n",
    "    \n",
    "    # Draw rectangles on the copied image\n",
    "    for (x, y, w, h) in rectangles:\n",
    "        # Determine the box positions\n",
    "        top_left = (x, y)\n",
    "        bottom_right = (x + w, y + h)\n",
    "        # Draw the rectangle\n",
    "        image_with_boxes = cv2.rectangle(image_with_boxes, top_left, bottom_right, line_color, thickness=cv2.LINE_4)\n",
    "\n",
    "    return image_with_boxes\n",
    "\n",
    "\n",
    "def draw_yolo_mask(canvas, masks, random_color=False, borders=True):\n",
    "    \"\"\"\n",
    "    Draws the segmentation masks onto the canvas image, resizing them if necessary.\n",
    "\n",
    "    Args:\n",
    "        canvas (numpy.ndarray): The image on which to draw the masks.\n",
    "        masks (torch.Tensor): A tensor of shape [number of masks, height, width] containing the mask data.\n",
    "        random_color (bool): If True, each mask will be drawn with a random color. Default is False.\n",
    "        borders (bool): If True, borders will be drawn around the masks. Default is True.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The canvas image with the masks drawn.\n",
    "    \"\"\"\n",
    "    # Get the dimensions of the canvas\n",
    "    canvas_height, canvas_width = canvas.shape[:2]\n",
    "\n",
    "    # Loop over each mask\n",
    "    for mask in masks:\n",
    "        \n",
    "        # Resize the mask to fit the canvas size\n",
    "        #resized_mask = cv2.resize(mask, (canvas_width, canvas_height), interpolation=cv2.INTER_NEAREST)\n",
    "        \n",
    "        if random_color:\n",
    "            color = [random.randint(0, 255) for _ in range(3)]  # Generate a random color\n",
    "        else:\n",
    "            color = (0, 255, 0)  # Default green color\n",
    "        \n",
    "        # Create a color image for the mask\n",
    "        colored_mask = np.zeros_like(canvas, dtype=np.uint8)\n",
    "        colored_mask[mask > 0] = color\n",
    "        \n",
    "        # Overlay the mask onto the canvas\n",
    "        canvas = cv2.addWeighted(canvas, 1.0, colored_mask, 0.5, 0)\n",
    "        \n",
    "        if borders:\n",
    "            # Find contours around the mask\n",
    "            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            # Try to smooth contours\n",
    "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "            mask_image = cv2.drawContours(canvas, contours, -1, (1, 1, 1, 0.5), thickness=2) \n",
    "    \n",
    "    return mask_image\n",
    "\n",
    "\n",
    "def draw_sam2_mask(canvas, masks, random_color=False, borders=True):\n",
    "    \"\"\"\n",
    "    Draws the segmentation masks onto the canvas image.\n",
    "    Args:\n",
    "        canvas (numpy.ndarray): The image on which to draw the masks.\n",
    "        masks (numpy.ndarray): A numpy array of shape [num_predicted_masks_per_input, height, width]\n",
    "                               or [num_predicted_masks_per_input, batch_size, height, width] containing the mask data.\n",
    "        random_color (bool): If True, each mask will be drawn with a random color. Default is False.\n",
    "        borders (bool): If True, borders will be drawn around the masks. Default is True.\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: The canvas image with the masks drawn.\n",
    "    \"\"\"\n",
    "    \n",
    "    def process_mask(mask):\n",
    "        nonlocal result_canvas\n",
    "        if random_color:\n",
    "            color = [random.randint(0, 255) for _ in range(3)]\n",
    "        else:\n",
    "            color = [30, 144, 255]  # SAM2 default color\n",
    "        \n",
    "        alpha = 0.6\n",
    "        colored_mask = np.zeros_like(result_canvas, dtype=np.uint8)\n",
    "        colored_mask[mask > 0] = color\n",
    "        \n",
    "        result_canvas = cv2.addWeighted(result_canvas, 1.0, colored_mask, alpha, 0)\n",
    "\n",
    "        if borders:\n",
    "            contours, _ = cv2.findContours(mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n",
    "            cv2.drawContours(result_canvas, contours, -1, (255, 255, 255), thickness=2)\n",
    "    \n",
    "    result_canvas = canvas.copy()\n",
    "    \n",
    "    print(masks.shape)\n",
    "    if masks.ndim == 3:\n",
    "        # Single bbox case: [num_predicted_masks_per_input, height, width]\n",
    "        for mask in masks:\n",
    "            process_mask(mask)\n",
    "    elif masks.ndim == 4:\n",
    "        # Multiple bboxes case: [num_predicted_masks_per_input, batch_size, height, width]\n",
    "        # Process each mask in batch\n",
    "        for batch_idx in range(masks.shape[1]):\n",
    "            for mask in masks[:, batch_idx]:\n",
    "                process_mask(mask)\n",
    "    else:\n",
    "        raise ValueError(\"Unexpected masks dimensions. Expected 3D or 4D input.\")\n",
    "    \n",
    "    return result_canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions to show results of SAM2 segmentations, using Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_functions import show_mask, show_points, show_box, show_masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility functions to show results of SAM2 segmentations, using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility_functions import draw_masks_on_image, draw_points, draw_boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the YOLO and SAM2 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "yolo_checkpoint = \"yolo-sam-2/yolo_weights/Salmons_YOLOv8.pt\"\n",
    "yolo_segmentator = YOLO(model=yolo_checkpoint, task=\"segment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sam2.build_sam import build_sam2\n",
    "from sam2.sam2_image_predictor import SAM2ImagePredictor\n",
    "\n",
    "sam2_checkpoint = \"checkpoints/sam2_hiera_large.pt\"\n",
    "model_cfg = \"sam2_hiera_l.yaml\"\n",
    "\n",
    "sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=\"cuda\")\n",
    "\n",
    "predictor = SAM2ImagePredictor(sam2_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images from video\n",
    "Frames are stored in a list of paths for each video frame, each frame is stored as a JPEG. This is not necesary when using the SAM2ImagePredictor class but is necesary for the SAM2VideoPredictor, so the code is shown here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `video_dir` a directory of JPEG frames with filenames like `<frame_index>.jpg`\n",
    "video_dir = \"yolo-sam-2/videos/SHORT_verde\"\n",
    "\n",
    "# scan all the JPEG frame names in this directory\n",
    "frame_names = [\n",
    "    p for p in os.listdir(video_dir)\n",
    "    if os.path.splitext(p)[-1] in [\".jpg\", \".jpeg\", \".JPG\", \".JPEG\"]\n",
    "]\n",
    "frame_names.sort(key=lambda p: int(os.path.splitext(p)[0]))\n",
    "frame_paths = [os.path.join(video_dir, frame_name) for frame_name in frame_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image using OpenCV\n",
    "image = cv2.imread(frame_paths[60])\n",
    "\n",
    "# Convert the image to RGB (OpenCV loads images in BGR by default)\n",
    "image_RGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_RGB)\n",
    "plt.axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the image using OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Truck Image', cv2.resize(image, (image.shape[1] // 2, image.shape[0] // 2)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain image bounding box using a YOLO detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(yolo_model: YOLO, image):\n",
    "    #segmentation_result = yolo_model.track(source=image, persist=True)\n",
    "    segmentation_result = yolo_model.predict(source=image)\n",
    "    yolo_bounding_boxes = np.array([bb.cpu().numpy() for bb in segmentation_result[0].boxes.xyxy], dtype=np.int16)\n",
    "    return yolo_bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the bboxes with YOLO\n",
    "input_boxes = get_bbox(yolo_segmentator, image)\n",
    "# Set the SAM2 predictor to the image\n",
    "predictor.set_image(image_RGB)\n",
    "\n",
    "input_boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do inference with SAM2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks, scores, logits = predictor.predict(\n",
    "    point_coords=None,\n",
    "    point_labels=None,\n",
    "    box=input_boxes,\n",
    "    multimask_output=False,\n",
    ")\n",
    "masks.shape # (number of masks, batches (multimask_output), H, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image_RGB)\n",
    "for mask in masks:\n",
    "    show_mask(mask.squeeze(0), plt.gca(), random_color=True)\n",
    "for box in input_boxes:\n",
    "    show_box(box, plt.gca())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show results with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_with_boxes = draw_boxes(image, input_boxes)\n",
    "image_with_masks = draw_masks_on_image(image_with_boxes, masks, random_color=True, borders=True)\n",
    "\n",
    "cv2.imshow('Image with Masks', cv2.resize(image_with_masks, (image_with_masks.shape[1] // 2, image_with_masks.shape[0] // 2)))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
